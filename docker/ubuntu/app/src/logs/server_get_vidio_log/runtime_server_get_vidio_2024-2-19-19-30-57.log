2024-02-19 19:30:58.010 | INFO     | __main__:create_log_file:34 - /app/ubuntu/app/src/logs/server_get_vidio_log/runtime_server_get_vidio_2024-2-19-19-30-57.log
2024-02-19 19:30:58.010 | INFO     | __main__:start_server_get_vidio:57 - Start get_video_server
2024-02-19 19:31:03.777 | INFO     | asyncio.events:_run:80 - An error has been caught in function '_run', process 'MainProcess' (5153), thread 'MainThread' (140625832615936):
Traceback (most recent call last):

  File "/usr/local/lib/python3.11/dist-packages/pyspark/serializers.py", line 459, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
           │           │     │    └ 5
           │           │     └ (<function DataStreamWriter._construct_foreach_function.<locals>.func_without_process at 0x7fe5cb6ca7a0>, None, AutoBatchedSe...
           │           └ <function dumps at 0x7fe5cbaddd00>
           └ <module 'pyspark.cloudpickle' from '/usr/local/lib/python3.11/dist-packages/pyspark/cloudpickle/__init__.py'>
  File "/usr/local/lib/python3.11/dist-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 73, in dumps
    cp.dump(obj)
    │  │    └ (<function DataStreamWriter._construct_foreach_function.<locals>.func_without_process at 0x7fe5cb6ca7a0>, None, AutoBatchedSe...
    │  └ <function CloudPickler.dump at 0x7fe5cbadf240>
    └ <pyspark.cloudpickle.cloudpickle_fast.CloudPickler object at 0x7fe5cb776d50>
  File "/usr/local/lib/python3.11/dist-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 632, in dump
    return Pickler.dump(self, obj)
           │       │    │     └ (<function DataStreamWriter._construct_foreach_function.<locals>.func_without_process at 0x7fe5cb6ca7a0>, None, AutoBatchedSe...
           │       │    └ <pyspark.cloudpickle.cloudpickle_fast.CloudPickler object at 0x7fe5cb776d50>
           │       └ <method 'dump' of '_pickle.Pickler' objects>
           └ <class '_pickle.Pickler'>

TypeError: cannot pickle 'cimpl.Producer' object


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/app/ubuntu/app/src/server_get_video.py", line 76, in <module>
    run(start_server_get_vidio())
    │   └ <function start_server_get_vidio at 0x7fe5cb631800>
    └ <function run at 0x7fe600263380>

  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           │      │   └ <coroutine object start_server_get_vidio at 0x7fe5cb77f640>
           │      └ <function Runner.run at 0x7fe6000aeca0>
           └ <asyncio.runners.Runner object at 0x7fe5cb823310>
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           │    │     │                  └ <Task pending name='Task-1' coro=<start_server_get_vidio() running at /usr/local/lib/python3.11/dist-packages/loguru/_logger....
           │    │     └ <function BaseEventLoop.run_until_complete at 0x7fe6000ac900>
           │    └ <_UnixSelectorEventLoop running=True closed=False debug=False>
           └ <asyncio.runners.Runner object at 0x7fe5cb823310>
  File "/usr/lib/python3.11/asyncio/base_events.py", line 640, in run_until_complete
    self.run_forever()
    │    └ <function BaseEventLoop.run_forever at 0x7fe6000ac860>
    └ <_UnixSelectorEventLoop running=True closed=False debug=False>
  File "/usr/lib/python3.11/asyncio/base_events.py", line 607, in run_forever
    self._run_once()
    │    └ <function BaseEventLoop._run_once at 0x7fe6000ae660>
    └ <_UnixSelectorEventLoop running=True closed=False debug=False>
  File "/usr/lib/python3.11/asyncio/base_events.py", line 1922, in _run_once
    handle._run()
    │      └ <function Handle._run at 0x7fe600210c20>
    └ <Handle <TaskStepMethWrapper object at 0x7fe5cb61b220>()>
> File "/usr/lib/python3.11/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
    │    │            │    │           │    └ <member '_args' of 'Handle' objects>
    │    │            │    │           └ <Handle <TaskStepMethWrapper object at 0x7fe5cb61b220>()>
    │    │            │    └ <member '_callback' of 'Handle' objects>
    │    │            └ <Handle <TaskStepMethWrapper object at 0x7fe5cb61b220>()>
    │    └ <member '_context' of 'Handle' objects>
    └ <Handle <TaskStepMethWrapper object at 0x7fe5cb61b220>()>

  File "/app/ubuntu/app/src/server_get_video.py", line 71, in start_server_get_vidio
    kafka_stream.writeStream.foreach(lambda msg: get_frame(msg, redis, producer)).start()
    │            │                               │              │      └ <cimpl.Producer object at 0x7fe5cb6cad40>
    │            │                               │              └ Redis<ConnectionPool<Connection<host=172.18.0.6,port=6379,db=0>>>
    │            │                               └ <function get_frame at 0x7fe600c39f80>
    │            └ <property object at 0x7fe5cb7409f0>
    └ DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]

  File "/usr/local/lib/python3.11/dist-packages/pyspark/sql/streaming/readwriter.py", line 1384, in foreach
    wrapped_func = _wrap_function(self._spark._sc, func, serializer, serializer)
                   │              │    │      │    │     │           └ AutoBatchedSerializer(CloudPickleSerializer())
                   │              │    │      │    │     └ AutoBatchedSerializer(CloudPickleSerializer())
                   │              │    │      │    └ <function DataStreamWriter._construct_foreach_function.<locals>.func_without_process at 0x7fe5cb6ca7a0>
                   │              │    │      └ <SparkContext master=local[*] appName=KafkaStream>
                   │              │    └ <pyspark.sql.session.SparkSession object at 0x7fe5ffe6b750>
                   │              └ <pyspark.sql.streaming.readwriter.DataStreamWriter object at 0x7fe5cbdcba10>
                   └ <function _wrap_function at 0x7fe5cb997880>
  File "/usr/local/lib/python3.11/dist-packages/pyspark/rdd.py", line 5268, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
                                                     │                       │   └ (<function DataStreamWriter._construct_foreach_function.<locals>.func_without_process at 0x7fe5cb6ca7a0>, None, AutoBatchedSe...
                                                     │                       └ <SparkContext master=local[*] appName=KafkaStream>
                                                     └ <function _prepare_for_python_RDD at 0x7fe5cb981b20>
  File "/usr/local/lib/python3.11/dist-packages/pyspark/rdd.py", line 5251, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
                      │   │     └ (<function DataStreamWriter._construct_foreach_function.<locals>.func_without_process at 0x7fe5cb6ca7a0>, None, AutoBatchedSe...
                      │   └ <function CloudPickleSerializer.dumps at 0x7fe5cbae5440>
                      └ CloudPickleSerializer()
  File "/usr/local/lib/python3.11/dist-packages/pyspark/serializers.py", line 469, in dumps
    raise pickle.PicklingError(msg)
          │      │             └ "Could not serialize object: TypeError: cannot pickle 'cimpl.Producer' object"
          │      └ <class '_pickle.PicklingError'>
          └ <module 'pickle' from '/usr/lib/python3.11/pickle.py'>

_pickle.PicklingError: Could not serialize object: TypeError: cannot pickle 'cimpl.Producer' object
