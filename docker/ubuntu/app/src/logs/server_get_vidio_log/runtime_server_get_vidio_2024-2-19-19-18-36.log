2024-02-19 19:18:36.608 | INFO     | __main__:create_log_file:38 - /app/ubuntu/app/src/logs/server_get_vidio_log/runtime_server_get_vidio_2024-2-19-19-18-36.log
2024-02-19 19:18:36.608 | INFO     | __main__:start_server_get_vidio:61 - Start get_video_server
2024-02-19 19:18:42.350 | INFO     | asyncio.events:_run:80 - An error has been caught in function '_run', process 'MainProcess' (4744), thread 'MainThread' (140555329335296):
Traceback (most recent call last):

  File "/usr/local/lib/python3.11/dist-packages/pyspark/serializers.py", line 459, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
           │           │     │    └ 5
           │           │     └ (<function DataStreamWriter._construct_foreach_function.<locals>.func_without_process at 0x7fd5611bed40>, None, AutoBatchedSe...
           │           └ <function dumps at 0x7fd5615c9e40>
           └ <module 'pyspark.cloudpickle' from '/usr/local/lib/python3.11/dist-packages/pyspark/cloudpickle/__init__.py'>
  File "/usr/local/lib/python3.11/dist-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 73, in dumps
    cp.dump(obj)
    │  │    └ (<function DataStreamWriter._construct_foreach_function.<locals>.func_without_process at 0x7fd5611bed40>, None, AutoBatchedSe...
    │  └ <function CloudPickler.dump at 0x7fd5615cb380>
    └ <pyspark.cloudpickle.cloudpickle_fast.CloudPickler object at 0x7fd56126b590>
  File "/usr/local/lib/python3.11/dist-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 632, in dump
    return Pickler.dump(self, obj)
           │       │    │     └ (<function DataStreamWriter._construct_foreach_function.<locals>.func_without_process at 0x7fd5611bed40>, None, AutoBatchedSe...
           │       │    └ <pyspark.cloudpickle.cloudpickle_fast.CloudPickler object at 0x7fd56126b590>
           │       └ <method 'dump' of '_pickle.Pickler' objects>
           └ <class '_pickle.Pickler'>

TypeError: cannot pickle '_thread.lock' object


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/app/ubuntu/app/src/server_get_video.py", line 75, in <module>
    run(start_server_get_vidio())
    │   └ <function start_server_get_vidio at 0x7fd5611259e0>
    └ <function run at 0x7fd595d334c0>

  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           │      │   └ <coroutine object start_server_get_vidio at 0x7fd56126f740>
           │      └ <function Runner.run at 0x7fd595b7ede0>
           └ <asyncio.runners.Runner object at 0x7fd56112acd0>
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           │    │     │                  └ <Task pending name='Task-1' coro=<start_server_get_vidio() running at /usr/local/lib/python3.11/dist-packages/loguru/_logger....
           │    │     └ <function BaseEventLoop.run_until_complete at 0x7fd595b7ca40>
           │    └ <_UnixSelectorEventLoop running=True closed=False debug=False>
           └ <asyncio.runners.Runner object at 0x7fd56112acd0>
  File "/usr/lib/python3.11/asyncio/base_events.py", line 640, in run_until_complete
    self.run_forever()
    │    └ <function BaseEventLoop.run_forever at 0x7fd595b7c9a0>
    └ <_UnixSelectorEventLoop running=True closed=False debug=False>
  File "/usr/lib/python3.11/asyncio/base_events.py", line 607, in run_forever
    self._run_once()
    │    └ <function BaseEventLoop._run_once at 0x7fd595b7e7a0>
    └ <_UnixSelectorEventLoop running=True closed=False debug=False>
  File "/usr/lib/python3.11/asyncio/base_events.py", line 1922, in _run_once
    handle._run()
    │      └ <function Handle._run at 0x7fd595ce0d60>
    └ <Handle <TaskStepMethWrapper object at 0x7fd561117070>()>
> File "/usr/lib/python3.11/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
    │    │            │    │           │    └ <member '_args' of 'Handle' objects>
    │    │            │    │           └ <Handle <TaskStepMethWrapper object at 0x7fd561117070>()>
    │    │            │    └ <member '_callback' of 'Handle' objects>
    │    │            └ <Handle <TaskStepMethWrapper object at 0x7fd561117070>()>
    │    └ <member '_context' of 'Handle' objects>
    └ <Handle <TaskStepMethWrapper object at 0x7fd561117070>()>

  File "/app/ubuntu/app/src/server_get_video.py", line 70, in start_server_get_vidio
    query_cons = init_spark_cons(spark)
                 │               └ <pyspark.sql.session.SparkSession object at 0x7fd55b710790>
                 └ <function init_spark_cons at 0x7fd561125620>

  File "/app/ubuntu/app/src/server_get_video.py", line 56, in init_spark_cons
    return kafka_stream.writeStream.foreach(get_frame).start()
           │            │                   └ <function get_frame at 0x7fd56cae2340>
           │            └ <property object at 0x7fd561230ae0>
           └ DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]

  File "/usr/local/lib/python3.11/dist-packages/pyspark/sql/streaming/readwriter.py", line 1384, in foreach
    wrapped_func = _wrap_function(self._spark._sc, func, serializer, serializer)
                   │              │    │      │    │     │           └ AutoBatchedSerializer(CloudPickleSerializer())
                   │              │    │      │    │     └ AutoBatchedSerializer(CloudPickleSerializer())
                   │              │    │      │    └ <function DataStreamWriter._construct_foreach_function.<locals>.func_without_process at 0x7fd5611bed40>
                   │              │    │      └ <SparkContext master=local[*] appName=KafkaStream>
                   │              │    └ <pyspark.sql.session.SparkSession object at 0x7fd55b710790>
                   │              └ <pyspark.sql.streaming.readwriter.DataStreamWriter object at 0x7fd5625a6ed0>
                   └ <function _wrap_function at 0x7fd56148b9c0>
  File "/usr/local/lib/python3.11/dist-packages/pyspark/rdd.py", line 5268, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
                                                     │                       │   └ (<function DataStreamWriter._construct_foreach_function.<locals>.func_without_process at 0x7fd5611bed40>, None, AutoBatchedSe...
                                                     │                       └ <SparkContext master=local[*] appName=KafkaStream>
                                                     └ <function _prepare_for_python_RDD at 0x7fd561475c60>
  File "/usr/local/lib/python3.11/dist-packages/pyspark/rdd.py", line 5251, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
                      │   │     └ (<function DataStreamWriter._construct_foreach_function.<locals>.func_without_process at 0x7fd5611bed40>, None, AutoBatchedSe...
                      │   └ <function CloudPickleSerializer.dumps at 0x7fd5615d1580>
                      └ CloudPickleSerializer()
  File "/usr/local/lib/python3.11/dist-packages/pyspark/serializers.py", line 469, in dumps
    raise pickle.PicklingError(msg)
          │      │             └ "Could not serialize object: TypeError: cannot pickle '_thread.lock' object"
          │      └ <class '_pickle.PicklingError'>
          └ <module 'pickle' from '/usr/lib/python3.11/pickle.py'>

_pickle.PicklingError: Could not serialize object: TypeError: cannot pickle '_thread.lock' object
